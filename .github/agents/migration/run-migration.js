#!/usr/bin/env node

const { Octokit } = require('@octokit/rest');
const { createClient } = require('@supabase/supabase-js');
const fs = require('fs').promises;
const path = require('path');
const { exec } = require('child_process');
const { promisify } = require('util');
const { DashboardReporter } = require('../shared/dashboard-reporter');

const execAsync = promisify(exec);

/**
 * Migration Agent for Supabase Database Operations
 * Handles schema migration from dev to production, data validation,
 * Edge function deployment, and configuration management
 */
class MigrationAgent {
  constructor(config) {
    this.config = config;
    this.agentId = config.agentId || `migration-agent-${Date.now()}`;
    
    // Initialize GitHub client
    this.octokit = new Octokit({
      auth: process.env.GITHUB_TOKEN || process.argv.find(arg => arg.includes('--github-token'))?.split('=')[1]
    });
    
    // Initialize dashboard reporter
    this.reporter = new DashboardReporter(this.agentId, 'migration');
    
    // Initialize Supabase clients
    this.devSupabase = createClient(
      process.env.DEV_SUPABASE_URL || config.dev.url,
      process.env.DEV_SUPABASE_ANON_KEY || config.dev.anonKey
    );
    
    this.prodSupabase = createClient(
      process.env.PROD_SUPABASE_URL || config.prod.url,
      process.env.PROD_SUPABASE_SERVICE_KEY || config.prod.serviceKey
    );
    
    // Migration state
    this.migrationState = {
      phase: 'pending',
      steps: [],
      errors: [],
      rollbackPlan: []
    };
  }

  /**
   * Main migration orchestrator
   */
  async runMigration(phase = 'full') {
    console.log(`üóÑÔ∏è Starting Supabase migration - Phase: ${phase}`);
    
    await this.reporter.reportStatus('active', {
      currentTask: `Running ${phase} migration`,
      phase
    });
    
    await this.reporter.logActivity(
      'migration_started',
      `Started ${phase} migration`,
      `Migrating from dev to production Supabase`
    );
    
    try {
      switch (phase) {
        case 'prepare':
          await this.prepareMigration();
          break;
        case 'schema':
          await this.migrateSchema();
          break;
        case 'data':
          await this.migrateData();
          break;
        case 'functions':
          await this.migrateFunctions();
          break;
        case 'config':
          await this.migrateConfiguration();
          break;
        case 'verify':
          await this.verifyMigration();
          break;
        case 'full':
          await this.runFullMigration();
          break;
        case 'rollback':
          await this.rollbackMigration();
          break;
        default:
          throw new Error(`Unknown migration phase: ${phase}`);
      }
      
      await this.reporter.reportStatus('idle', {
        lastMigration: phase,
        completedAt: new Date()
      });
      
      await this.reporter.logActivity(
        'migration_completed',
        `Completed ${phase} migration`,
        `Migration successful`
      );
      
      return {
        success: true,
        phase,
        state: this.migrationState
      };
      
    } catch (error) {
      await this.handleMigrationError(error, phase);
      throw error;
    }
  }

  /**
   * Full migration workflow
   */
  async runFullMigration() {
    const phases = ['prepare', 'schema', 'data', 'functions', 'config', 'verify'];
    
    for (const phase of phases) {
      console.log(`\nüìã Executing phase: ${phase}`);
      this.migrationState.phase = phase;
      
      switch (phase) {
        case 'prepare':
          await this.prepareMigration();
          break;
        case 'schema':
          await this.migrateSchema();
          break;
        case 'data':
          await this.migrateData();
          break;
        case 'functions':
          await this.migrateFunctions();
          break;
        case 'config':
          await this.migrateConfiguration();
          break;
        case 'verify':
          await this.verifyMigration();
          break;
      }
      
      this.migrationState.steps.push({
        phase,
        completedAt: new Date(),
        status: 'completed'
      });
    }
  }

  /**
   * Prepare migration - backup and analysis
   */
  async prepareMigration() {
    console.log('üîç Preparing migration...');
    
    // Create backup of production database
    await this.createBackup();
    
    // Analyze dev schema
    const devSchema = await this.analyzeSchema(this.devSupabase);
    
    // Analyze prod schema
    const prodSchema = await this.analyzeSchema(this.prodSupabase);
    
    // Generate migration plan
    const migrationPlan = await this.generateMigrationPlan(devSchema, prodSchema);
    
    // Generate rollback plan
    this.migrationState.rollbackPlan = await this.generateRollbackPlan(prodSchema);
    
    // Save migration artifacts
    await this.saveMigrationArtifacts({
      devSchema,
      prodSchema,
      migrationPlan,
      rollbackPlan: this.migrationState.rollbackPlan
    });
    
    console.log('‚úÖ Migration preparation completed');
  }

  /**
   * Migrate database schema
   */
  async migrateSchema() {
    console.log('üèóÔ∏è Migrating schema...');
    
    // Get pending migrations from dev
    const { data: devMigrations } = await this.devSupabase
      .from('supabase_migrations.schema_migrations')
      .select('*')
      .order('version', { ascending: true });
    
    // Get applied migrations from prod
    const { data: prodMigrations } = await this.prodSupabase
      .from('supabase_migrations.schema_migrations')
      .select('*')
      .order('version', { ascending: true });
    
    const prodVersions = new Set(prodMigrations?.map(m => m.version) || []);
    const pendingMigrations = devMigrations?.filter(m => !prodVersions.has(m.version)) || [];
    
    console.log(`üìù Found ${pendingMigrations.length} pending migrations`);
    
    // Apply each migration
    for (const migration of pendingMigrations) {
      console.log(`  Applying migration: ${migration.version}`);
      
      try {
        // Read migration file
        const migrationPath = path.join('./supabase/migrations', `${migration.version}_${migration.name}.sql`);
        const migrationSQL = await fs.readFile(migrationPath, 'utf8');
        
        // Apply to production
        const { error } = await this.prodSupabase.rpc('exec_sql', {
          sql: migrationSQL
        });
        
        if (error) {
          throw new Error(`Migration failed: ${error.message}`);
        }
        
        console.log(`  ‚úÖ Applied: ${migration.version}`);
        
      } catch (error) {
        console.error(`  ‚ùå Failed: ${migration.version} - ${error.message}`);
        throw error;
      }
    }
    
    console.log('‚úÖ Schema migration completed');
  }

  /**
   * Migrate critical data
   */
  async migrateData() {
    console.log('üìä Migrating data...');
    
    const criticalTables = [
      'wedding_events',
      'user_profiles',
      'venue_information',
      'guest_lists'
    ];
    
    for (const table of criticalTables) {
      console.log(`  Syncing table: ${table}`);
      
      try {
        // Get data from dev
        const { data: devData, error: devError } = await this.devSupabase
          .from(table)
          .select('*');
        
        if (devError) {
          console.log(`  ‚ö†Ô∏è Skipping ${table}: ${devError.message}`);
          continue;
        }
        
        if (!devData || devData.length === 0) {
          console.log(`  üìù No data in ${table}`);
          continue;
        }
        
        // Validate data before migration
        const validatedData = await this.validateData(table, devData);
        
        // Upsert to production (only if it doesn't exist)
        const { error: prodError } = await this.prodSupabase
          .from(table)
          .upsert(validatedData, { onConflict: 'id' });
        
        if (prodError) {
          throw new Error(`Data migration failed for ${table}: ${prodError.message}`);
        }
        
        console.log(`  ‚úÖ Synced ${validatedData.length} rows to ${table}`);
        
      } catch (error) {
        console.error(`  ‚ùå Failed to sync ${table}: ${error.message}`);
        throw error;
      }
    }
    
    console.log('‚úÖ Data migration completed');
  }

  /**
   * Migrate Edge Functions
   */
  async migrateFunctions() {
    console.log('‚ö° Migrating Edge Functions...');
    
    const functionsDir = './supabase/functions';
    
    try {
      const functionDirs = await fs.readdir(functionsDir);
      
      for (const functionName of functionDirs) {
        const functionPath = path.join(functionsDir, functionName);
        const stat = await fs.stat(functionPath);
        
        if (stat.isDirectory()) {
          console.log(`  Deploying function: ${functionName}`);
          
          try {
            // Deploy using Supabase CLI
            const { stdout, stderr } = await execAsync(
              `supabase functions deploy ${functionName} --project-ref ${this.config.prod.projectRef}`,
              { cwd: '.' }
            );
            
            if (stderr && !stderr.includes('warning')) {
              throw new Error(stderr);
            }
            
            console.log(`  ‚úÖ Deployed: ${functionName}`);
            
          } catch (error) {
            console.error(`  ‚ùå Failed to deploy ${functionName}: ${error.message}`);
            throw error;
          }
        }
      }
      
    } catch (error) {
      if (error.code === 'ENOENT') {
        console.log('  üìù No Edge Functions directory found');
      } else {
        throw error;
      }
    }
    
    console.log('‚úÖ Edge Functions migration completed');
  }

  /**
   * Migrate configuration and secrets
   */
  async migrateConfiguration() {
    console.log('‚öôÔ∏è Migrating configuration...');
    
    // Update GitHub secrets with production URLs
    await this.updateGitHubSecrets();
    
    // Update environment variables
    await this.updateEnvironmentVariables();
    
    // Update Netlify configuration
    await this.updateNetlifyConfig();
    
    console.log('‚úÖ Configuration migration completed');
  }

  /**
   * Verify migration success
   */
  async verifyMigration() {
    console.log('üîç Verifying migration...');
    
    const verificationResults = {
      schema: false,
      data: false,
      functions: false,
      connectivity: false
    };
    
    // Verify schema
    try {
      const prodSchema = await this.analyzeSchema(this.prodSupabase);
      verificationResults.schema = prodSchema.tables.length > 0;
      console.log(`  ‚úÖ Schema: ${prodSchema.tables.length} tables`);
    } catch (error) {
      console.error(`  ‚ùå Schema verification failed: ${error.message}`);
    }
    
    // Verify data
    try {
      const { data, error } = await this.prodSupabase
        .from('wedding_events')
        .select('count', { count: 'exact' });
      
      verificationResults.data = !error;
      console.log(`  ‚úÖ Data: Tables accessible`);
    } catch (error) {
      console.error(`  ‚ùå Data verification failed: ${error.message}`);
    }
    
    // Verify connectivity
    try {
      const { data, error } = await this.prodSupabase
        .from('_health_check')
        .select('*')
        .limit(1);
      
      verificationResults.connectivity = !error || error.code === 'PGRST116'; // Table not found is OK
      console.log(`  ‚úÖ Connectivity: Database accessible`);
    } catch (error) {
      console.error(`  ‚ùå Connectivity verification failed: ${error.message}`);
    }
    
    const allPassed = Object.values(verificationResults).every(result => result);
    
    if (allPassed) {
      console.log('‚úÖ Migration verification completed successfully');
    } else {
      throw new Error('Migration verification failed');
    }
    
    return verificationResults;
  }

  /**
   * Rollback migration
   */
  async rollbackMigration() {
    console.log('üîÑ Rolling back migration...');
    
    if (!this.migrationState.rollbackPlan || this.migrationState.rollbackPlan.length === 0) {
      throw new Error('No rollback plan available');
    }
    
    // Execute rollback steps in reverse order
    for (const step of this.migrationState.rollbackPlan.reverse()) {
      console.log(`  Executing rollback: ${step.description}`);
      
      try {
        await this.executeRollbackStep(step);
        console.log(`  ‚úÖ Completed: ${step.description}`);
      } catch (error) {
        console.error(`  ‚ùå Failed: ${step.description} - ${error.message}`);
        throw error;
      }
    }
    
    console.log('‚úÖ Rollback completed');
  }

  // Helper methods

  async analyzeSchema(supabaseClient) {
    const { data: tables, error } = await supabaseClient
      .rpc('get_schema_tables');
    
    if (error) {
      throw new Error(`Schema analysis failed: ${error.message}`);
    }
    
    return {
      tables: tables || [],
      analyzedAt: new Date()
    };
  }

  async generateMigrationPlan(devSchema, prodSchema) {
    const plan = {
      newTables: [],
      modifiedTables: [],
      newColumns: [],
      migrations: []
    };
    
    // Compare schemas and generate plan
    // This would include detailed schema diff logic
    
    return plan;
  }

  async generateRollbackPlan(prodSchema) {
    return [
      {
        type: 'backup_restore',
        description: 'Restore from backup',
        backupId: `backup_${Date.now()}`
      }
    ];
  }

  async createBackup() {
    console.log('üíæ Creating production backup...');
    
    try {
      // Create backup using Supabase CLI or API
      const backupId = `backup_${Date.now()}`;
      
      // In a real implementation, this would create an actual backup
      console.log(`  ‚úÖ Backup created: ${backupId}`);
      
      return backupId;
    } catch (error) {
      throw new Error(`Backup creation failed: ${error.message}`);
    }
  }

  async validateData(table, data) {
    // Data validation logic would go here
    // For now, return data as-is
    return data;
  }

  async updateGitHubSecrets() {
    console.log('  üîê Updating GitHub secrets...');
    
    const secrets = {
      VITE_SUPABASE_URL: this.config.prod.url,
      VITE_SUPABASE_ANON_KEY: this.config.prod.anonKey
    };
    
    // Update secrets via GitHub API
    // Implementation would depend on the specific repository setup
    
    console.log('  ‚úÖ GitHub secrets updated');
  }

  async updateEnvironmentVariables() {
    console.log('  üåç Updating environment variables...');
    
    // Update .env files or deployment configuration
    // Implementation specific to deployment platform
    
    console.log('  ‚úÖ Environment variables updated');
  }

  async updateNetlifyConfig() {
    console.log('  üåê Updating Netlify configuration...');
    
    // Update Netlify environment variables
    // Implementation would use Netlify API
    
    console.log('  ‚úÖ Netlify configuration updated');
  }

  async executeRollbackStep(step) {
    switch (step.type) {
      case 'backup_restore':
        // Restore from backup
        console.log(`    Restoring from backup: ${step.backupId}`);
        break;
      default:
        throw new Error(`Unknown rollback step type: ${step.type}`);
    }
  }

  async saveMigrationArtifacts(artifacts) {
    const outputDir = './migration-artifacts';
    await fs.mkdir(outputDir, { recursive: true });
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const artifactPath = path.join(outputDir, `migration-${timestamp}.json`);
    
    await fs.writeFile(
      artifactPath,
      JSON.stringify(artifacts, null, 2)
    );
    
    console.log(`  üìÅ Artifacts saved: ${artifactPath}`);
  }

  async handleMigrationError(error, phase) {
    console.error(`‚ùå Migration error in ${phase}:`, error);
    
    this.migrationState.errors.push({
      phase,
      error: error.message,
      timestamp: new Date()
    });
    
    await this.reporter.reportStatus('error', {
      error: error.message,
      phase,
      migrationState: this.migrationState
    });
    
    await this.reporter.logActivity(
      'migration_error',
      `Migration failed in ${phase}`,
      error.message
    );
  }
}

// Load configuration
async function loadConfig() {
  const configPath = process.env.MIGRATION_AGENT_CONFIG || 
                     path.join(__dirname, 'config.json');
  
  try {
    const configData = await fs.readFile(configPath, 'utf8');
    return JSON.parse(configData);
  } catch (error) {
    // Return default config if file not found
    return {
      dev: {
        url: process.env.DEV_SUPABASE_URL,
        anonKey: process.env.DEV_SUPABASE_ANON_KEY
      },
      prod: {
        url: process.env.PROD_SUPABASE_URL,
        serviceKey: process.env.PROD_SUPABASE_SERVICE_KEY,
        projectRef: process.env.PROD_SUPABASE_PROJECT_REF
      }
    };
  }
}

// Main execution
async function main() {
  const args = process.argv.slice(2);
  const phase = args.find(arg => arg.includes('--phase'))?.split('=')[1] || 'full';
  
  try {
    const config = await loadConfig();
    const agent = new MigrationAgent(config);
    const result = await agent.runMigration(phase);
    
    console.log('\nüéâ Migration completed successfully!');
    console.log(`Phase: ${result.phase}`);
    console.log(`Steps completed: ${result.state.steps.length}`);
    
  } catch (error) {
    console.error('üí• Migration failed:', error);
    process.exit(1);
  }
}

// Export for use by orchestrator
module.exports = { MigrationAgent };

// Run if called directly
if (require.main === module) {
  main();
}